{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "# 3.6.5  Polynomial Regression\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inserted cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file and save the results\n",
    "data = pd.read_csv('data/Boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the DataFrame (rows, columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form of polynomial linear regression with one input\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x + \\beta_2x^2 + ... + \\beta_nx^n$\n",
    "\n",
    "- $y$ is the response\n",
    "- $\\beta_0$ is the intercept\n",
    "\n",
    "\n",
    "##### What are the features?\n",
    "- **lstat:** percent of households with lower socioeconomic status (percent)\n",
    "\n",
    "##### What is the response?\n",
    "- **medv:** median value of owner-occupied homes (in $1000s)\n",
    "\n",
    "<br>\n",
    "$y = \\beta_0 + \\beta_1 \\times lstate + \\beta_2 \\times lstat^2 + ... + \\beta_n \\times lstat^n$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing X and y using pandas\n",
    "\n",
    "- scikit-learn expects X (feature matrix) and y (response vector) to be NumPy arrays.\n",
    "- However, pandas is built on top of NumPy.\n",
    "- Thus, X can be a pandas DataFrame and y can be a pandas Series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(6).reshape(3, 2)\n",
    "print(X)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "print(poly.fit_transform(X))\n",
    "# 1  x1  x2  x1^2  x1x2   x2^2\n",
    "\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "print(poly.fit_transform(X))\n",
    "#1 x1 x2  x1x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['lstat']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = data[feature_cols]\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type and shape of X\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a Series from the DataFrame\n",
    "y = data['medv']\n",
    "\n",
    "# equivalent command that works if there are no spaces in the column name\n",
    "y = data.medv\n",
    "\n",
    "# print the first 5 values\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type and shape of y\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default split is 75% for training and 25% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,random_state = 1)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 3) linear model coeff (w):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 3) linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 3) R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 3) R-squared score (test): {:.3f}\\n'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "print('\\nAddition of many polynomial features often leads to\\n\\\n",
    "overfitting, so we often use polynomial features in combination\\n\\\n",
    "with regression that has a regularization penalty, like ridge\\n\\\n",
    "regression.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 47.775 - 3.681 \\times lstat + 0.139 \\times lstat^2 - 0.0018 \\times lstat^3$\n",
    "\n",
    "- This is a statement of **association**, not **causation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an **evaluation metric** in order to compare our predictions with the actual values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing  $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## 3.6.5-1  Polynomial Regression with two input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form of the 2nd order polynomial linear regression with two input\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3 x_1^2 + \\beta_4 x_1 x_2 + \\beta_5 x_2^2$\n",
    "\n",
    "- $y$ is the response\n",
    "- $\\beta_0$ is the intercept\n",
    "\n",
    "\n",
    "##### What are the features?\n",
    "- **age:** average age of houses\n",
    "- **lstat:** percent of households with lower socioeconomic status (percent)\n",
    "\n",
    "##### What is the response?\n",
    "- **medv:** median value of owner-occupied homes (in $1000s)\n",
    "\n",
    "<br>\n",
    "$y = \\beta_0 + \\beta_1 \\times age + \\beta_2 \\times lstate + \\beta_3 \\times age^2 + \\beta_4 \\times age \\times lstat + \\beta_5 \\times lstat^2$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing X and y using pandas\n",
    "\n",
    "- scikit-learn expects X (feature matrix) and y (response vector) to be NumPy arrays.\n",
    "- However, pandas is built on top of NumPy.\n",
    "- Thus, X can be a pandas DataFrame and y can be a pandas Series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(6).reshape(3, 2)\n",
    "print(X)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "print(poly.fit_transform(X))\n",
    "# 1  x1  x2  x1^2  x1x2   x2^2\n",
    "\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "print(poly.fit_transform(X))\n",
    "#1 x1 x2  x1x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['age', 'lstat']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = data[feature_cols]\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type and shape of X\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a Series from the DataFrame\n",
    "y = data['medv']\n",
    "\n",
    "# equivalent command that works if there are no spaces in the column name\n",
    "y = data.medv\n",
    "\n",
    "# print the first 5 values\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type and shape of y\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default split is 75% for training and 25% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,random_state = 1)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 2) linear model coeff (w):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 2) linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}\\n'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "print('\\nAddition of many polynomial features often leads to\\n\\\n",
    "overfitting, so we often use polynomial features in combination\\n\\\n",
    "with regression that has a regularization penalty, like ridge\\n\\\n",
    "regression.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 38.780 + 0.0576 \\times age - 2.147 \\times lstate + 0.00058 \\times age^2 - 0.0074 \\times age \\times lstat + 0.053 \\times lstat^2$\n",
    "- This is a statement of **association**, not **causation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an **evaluation metric** in order to compare our predictions with the actual values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing  $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
