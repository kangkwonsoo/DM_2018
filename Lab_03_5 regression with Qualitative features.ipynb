{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# 3.6.6  Qualitative Predictors\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form of multiple linear regression\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "\n",
    "- $y$ is the response\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature)\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inserted cell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Income  Limit  Rating  Cards  Age  Education  Gender Student Married  \\\n",
      "0   14.891   3606     283      2   34         11    Male      No     Yes   \n",
      "1  106.025   6645     483      3   82         15  Female     Yes     Yes   \n",
      "2  104.593   7075     514      4   71         11    Male      No      No   \n",
      "3  148.924   9504     681      3   36         11  Female      No      No   \n",
      "4   55.882   4897     357      2   68         16    Male      No     Yes   \n",
      "\n",
      "   Ethnicity  Balance  \n",
      "0  Caucasian      333  \n",
      "1      Asian      903  \n",
      "2      Asian      580  \n",
      "3      Asian      964  \n",
      "4  Caucasian      331  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.891</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.025</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.593</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.924</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.882</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Ethnicity\n",
       "0   14.891  Caucasian\n",
       "1  106.025      Asian\n",
       "2  104.593      Asian\n",
       "3  148.924      Asian\n",
       "4   55.882  Caucasian"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read CSV file and save the results\n",
    "#data = pd.read_csv('data/Carseats.csv')\n",
    "data = pd.read_csv('data/Credit.csv')\n",
    "\n",
    "# display the first 5 rows\n",
    "print(data.head())\n",
    "\n",
    "# create a Python list of feature names\n",
    "feature_cols = ['Income', 'Ethnicity']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = data[feature_cols]\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "# check the type and shape of X\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    333\n",
       "1    903\n",
       "2    580\n",
       "3    964\n",
       "4    331\n",
       "Name: Balance, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a Series from the DataFrame\n",
    "y = data['Balance']\n",
    "\n",
    "# equivalent command that works if there are no spaces in the column name\n",
    "y = data.Balance\n",
    "\n",
    "# print the first 5 values\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "# check the type and shape of y\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Income  Ethnicity_African American  Ethnicity_Asian  Ethnicity_Caucasian\n",
      "0     14.891                           0                0                    1\n",
      "1    106.025                           0                1                    0\n",
      "2    104.593                           0                1                    0\n",
      "3    148.924                           0                1                    0\n",
      "4     55.882                           0                0                    1\n",
      "5     80.180                           0                0                    1\n",
      "6     20.996                           1                0                    0\n",
      "7     71.408                           0                1                    0\n",
      "8     15.125                           0                0                    1\n",
      "9     71.061                           1                0                    0\n",
      "10    63.095                           0                0                    1\n",
      "11    15.045                           0                0                    1\n",
      "12    80.616                           0                1                    0\n",
      "13    43.682                           0                0                    1\n",
      "14    19.144                           1                0                    0\n",
      "15    20.089                           1                0                    0\n",
      "16    53.598                           1                0                    0\n",
      "17    36.496                           0                1                    0\n",
      "18    49.570                           0                1                    0\n",
      "19    42.079                           0                1                    0\n",
      "20    17.700                           0                1                    0\n",
      "21    37.348                           0                0                    1\n",
      "22    20.103                           1                0                    0\n",
      "23    64.027                           1                0                    0\n",
      "24    10.742                           0                0                    1\n",
      "25    14.090                           1                0                    0\n",
      "26    42.471                           0                0                    1\n",
      "27    32.793                           1                0                    0\n",
      "28   186.634                           1                0                    0\n",
      "29    26.813                           0                0                    1\n",
      "..       ...                         ...              ...                  ...\n",
      "370   35.610                           0                0                    1\n",
      "371   39.116                           0                0                    1\n",
      "372   19.782                           0                0                    1\n",
      "373   55.412                           0                0                    1\n",
      "374   29.400                           0                0                    1\n",
      "375   20.974                           0                0                    1\n",
      "376   87.625                           1                0                    0\n",
      "377   28.144                           0                0                    1\n",
      "378   19.349                           0                0                    1\n",
      "379   53.308                           0                0                    1\n",
      "380  115.123                           1                0                    0\n",
      "381  101.788                           0                0                    1\n",
      "382   24.824                           0                0                    1\n",
      "383   14.292                           0                0                    1\n",
      "384   20.088                           1                0                    0\n",
      "385   26.400                           0                1                    0\n",
      "386   19.253                           1                0                    0\n",
      "387   16.529                           0                1                    0\n",
      "388   37.878                           0                0                    1\n",
      "389   83.948                           0                0                    1\n",
      "390  135.118                           0                1                    0\n",
      "391   73.327                           0                0                    1\n",
      "392   25.974                           0                1                    0\n",
      "393   17.316                           1                0                    0\n",
      "394   49.794                           0                0                    1\n",
      "395   12.096                           0                0                    1\n",
      "396   13.364                           1                0                    0\n",
      "397   57.872                           0                0                    1\n",
      "398   37.728                           0                0                    1\n",
      "399   18.701                           0                1                    0\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X=pd.get_dummies(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols=list(X)\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default split is 75% for training and 25% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pair the feature names with the coefficients\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 221.744 - 6.266 \\times Income - 53.975 \\times Ethnicity\\_African American + 19.799 \\times Ethnicity\\_Asian + 34.175 \\times Ethnicity\\_Caucasian$\n",
    "\n",
    "- This is a statement of **association**, not **causation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an **evaluation metric** in order to compare our predictions with the actual values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing  $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(linreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## sklearn 을 이용하여 categorical feature를 처리하는 방법\n",
    "\n",
    "본 수업에서는 다루지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When to use One Hot Encoding vs LabelEncoder vs DictVectorizor?\n",
    "\n",
    "There are some cases where LabelEncoder or DictVectorizor are useful, but these are quite limited in my opinion due to ordinality.\n",
    "\n",
    "LabelEncoder can turn [dog,cat,dog,mouse,cat] into [1,2,1,3,2], but then the imposed ordinality means that the average of dog and mouse is cat. Still there are algorithms like decision trees and random forests that can work with categorical variables just fine and LabelEncoder can be used to store values using less disk space.\n",
    "\n",
    "One-Hot-Encoding has a the advantage that the result is binary rather than ordinal and that everything sits in an orthogonal vector space. The disadvantage is that for high cardinality, the feature space can really blow up quickly and you start fighting with the curse of dimensionality. In these cases, I typically employ one-hot-encoding followed by PCA for dimensionality reduction. I find that the judicious combination of one-hot plus PCA can seldom be beat by other encoding schemes. PCA finds the linear overlap, so will naturally tend to group similar features into the same feature.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
